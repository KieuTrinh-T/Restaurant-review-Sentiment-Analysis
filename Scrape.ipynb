{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import googlemaps\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPE LINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Chrome browser instance\n",
    "service = Service(executable_path='D:\\Downloads\\chromedriver_win32')\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service = service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to the application home page\n",
    "url = 'https://www.google.com/maps'\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(district):\n",
    "    # find the search box element on the page\n",
    "    search_box = driver.find_element(By.ID, 'searchboxinput')\n",
    "\n",
    "    # type district into the search box\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(district)\n",
    "\n",
    "    # find the search button\n",
    "    search_button = driver.find_element(By.ID, 'searchbox-searchbutton')\n",
    "    # click search button\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    # type \"nhà hàng\" into the search box\n",
    "    search_box.clear()\n",
    "    search_box.send_keys('nhà hàng')\n",
    "\n",
    "    # find the search button\n",
    "    search_button = driver.find_element(By.ID, 'searchbox-searchbutton')\n",
    "    # click search button\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    SCROLL_PAUSE_TIME = 5\n",
    "    # Get div result\n",
    "    div = driver.find_element(By.CLASS_NAME, 'hfpxzc')\n",
    "    # scroll down \n",
    "    for i in range(0, 15):  \n",
    "        for j in range(0, 10):\n",
    "            div.send_keys(Keys.PAGE_DOWN) #press PAGE_DOWN\n",
    "        time.sleep(SCROLL_PAUSE_TIME) #ưait for loading\n",
    "    # get all links\n",
    "    links = [e.get_attribute('href') for e in driver.find_elements(By.CLASS_NAME, 'hfpxzc')]\n",
    "    districts = [district for i in range(len(links))]\n",
    "    links = pd.DataFrame({'district': districts, 'link': links})\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "244\n",
      "366\n",
      "488\n",
      "610\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "distric_list = ['Phú Nhuận', 'Bình Thạnh', 'Tân Bình', 'Quận 5', 'Quận 4']\n",
    "for district in distric_list:\n",
    "    df = pd.concat([df, get_links(district)], axis = 0)\n",
    "    df.to_csv('data/restaurant.csv', index = False)\n",
    "    print(len(df))\n",
    "driver.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Scrape Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 305 entries, 0 to 608\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   district  305 non-null    object\n",
      " 1   link      305 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 7.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('restaurant_link.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates(subset = ['link'])\n",
    "df.info()\n",
    "df.to_csv('restaurant_link.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open chrome and GG map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Chrome browser instance\n",
    "service = Service(executable_path='D:\\Downloads\\chromedriver_win32')\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service = service, options=options)\n",
    "# navigate to the application home page\n",
    "url = 'https://www.google.com/maps'\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResInfo(page_source, id):\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    # get restaurant info\n",
    "    name = soup.find('h1').text\n",
    "    try:\n",
    "        rating = soup.find('div', class_ = 'F7nice').find('span').find('span').text\n",
    "    except:\n",
    "        rating = np.nan\n",
    "    try:\n",
    "        rating_count = soup.find('div', class_ = 'F7nice').find_all('span')[10].text\n",
    "        rating_count = re.findall(r'\\d+', rating_count)[0]\n",
    "    except:\n",
    "        rating_count = 0\n",
    "    address = soup.find('div', class_ = 'rogA2c').find('div').text\n",
    "    item = pd.DataFrame({'id': id ,'name': name, 'rating': rating, 'rating_count': rating_count, 'address': address}, index = [0])\n",
    "    return item\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReview(res_id):\n",
    "    df_review = pd.DataFrame(columns=['res_id', 'review', 'rating'])\n",
    "    # click view more to view full of review\n",
    "    more_buttons = driver.find_elements(By.CLASS_NAME, 'w8nwRe')\n",
    "    for button in more_buttons:\n",
    "        button.click()\n",
    "        time.sleep(1)\n",
    "    # get review\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    reviews = soup.find_all('div', class_ = 'jJc9Ad')\n",
    "    for div in reviews:\n",
    "        rating = div.find('div',class_ = 'DU9Pgb').find('span').get('aria-label').split(' ')[0]\n",
    "        try:\n",
    "            review = div.find('div', class_='MyEned').find('span').text\n",
    "            \n",
    "        except:\n",
    "            review = '' #Someone just rate without review\n",
    "        item = pd.DataFrame({'res_id': res_id, 'review': review, 'rating': rating}, index = [0])\n",
    "        df_review = pd.concat([df_review, item], axis = 0)\n",
    "    return df_review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/maps/place/The+Little+Door/data=!4m7!3m6!1s0x31752facfe18575b:0xd4877dbf5e55b6ad!8m2!3d10.787121!4d106.692198!16s%2Fg%2F11gmwsb3p6!19sChIJW1cY_qwvdTERrbZVXr99h9Q?authuser=0&hl=en&rclk=1\n",
      "https://www.google.com/maps/place/C%C3%B4n+S%C6%A1n+Restaurant+%26+Lounge/data=!4m7!3m6!1s0x31752fac4bc9f27d:0x7f78b7bf9cd3d81f!8m2!3d10.7843201!4d106.6850108!16s%2Fg%2F11rp0hrv8z!19sChIJffLJS6wvdTERH9jTnL-3eH8?authuser=0&hl=en&rclk=1\n"
     ]
    }
   ],
   "source": [
    "for link in df['link'][:2]:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/166 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 30/166 [1:26:17<6:31:11, 172.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[0;32m     31\u001b[0m         button\u001b[39m.\u001b[39msend_keys(Keys\u001b[39m.\u001b[39mPAGE_DOWN) \u001b[39m#press PAGE_DOWN\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     time\u001b[39m.\u001b[39;49msleep(SCROLL_PAUSE_TIME) \u001b[39m#wait for loading\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m# scrape reviews\u001b[39;00m\n\u001b[0;32m     34\u001b[0m page_source \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mpage_source\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res_id = 139\n",
    "for link in tqdm(df['link'][res_id:]): \n",
    "    res_id += 1\n",
    "    df_restaurant = pd.DataFrame(columns=['id','name', 'rating', 'rating_count', 'address'])\n",
    "    df_review = pd.DataFrame(columns=['res_id', 'review', 'rating'])\n",
    "    driver.get(link)\n",
    "    time.sleep(5)\n",
    "    #get restaurant info\n",
    "    page_source = driver.page_source\n",
    "    df_restaurant = pd.concat([df_restaurant, getResInfo(page_source, res_id)], axis = 0)\n",
    "    #scroll down\n",
    "    SCROLL_PAUSE_TIME = 5\n",
    "    # Get and choose review tab and skip restaurant not having review\n",
    "    if(len(driver.find_elements(By.CLASS_NAME, 'hh2c6'))==3): \n",
    "        tab = driver.find_elements(By.CLASS_NAME, 'hh2c6')[1]\n",
    "    else:\n",
    "        continue\n",
    "    # if(driver.find_elements(By.CLASS_NAME, 'hh2c6')):\n",
    "    #     tab = driver.find_elements(By.CLASS_NAME, 'hh2c6')[1]\n",
    "    # else:\n",
    "    #     continue #skip some restaurant doesn't have review\n",
    "    tab.click()\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    if(page_source == driver.page_source):\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "    else:\n",
    "        # scroll down\n",
    "        button = driver.find_element(By.CLASS_NAME, 'g88MCb')\n",
    "        for i in range(0, 15):\n",
    "            for j in range(0, 10):\n",
    "                button.send_keys(Keys.PAGE_DOWN) #press PAGE_DOWN\n",
    "            time.sleep(SCROLL_PAUSE_TIME) #wait for loading\n",
    "        # scrape reviews\n",
    "        page_source = driver.page_source\n",
    "        df_review = pd.concat([df_review, getReview(res_id)], axis = 0)\n",
    "    if(res_id == 1):\n",
    "        header = True\n",
    "    else:\n",
    "        header = False\n",
    "    df_restaurant.to_csv('data/restaurants.csv', index = False, header=header, mode='a')\n",
    "    df_review.to_csv('reviews.csv', index = False, header=header, mode='a')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res_id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A very large place with spacious yard outdoor,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Based on 80_84 Tran Quoc Thao Str, District 3 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Great place to hang out with friends at weeken...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The place looks fancy from outside, so the pri...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Great food, fine dining. Beautiful private din...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  res_id                                             review rating\n",
       "0      1  A very large place with spacious yard outdoor,...      3\n",
       "0      1  Based on 80_84 Tran Quoc Thao Str, District 3 ...      4\n",
       "0      1  Great place to hang out with friends at weeken...      5\n",
       "0      1  The place looks fancy from outside, so the pri...      4\n",
       "0      1  Great food, fine dining. Beautiful private din...      5"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The place looks fancy from outside, so the price. I was not be impressed by the food itself but mostly the hospitality of the staffs from the entrance till we finished our dinner. 4 stars!'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    # click view more to view full of review\n",
    "more_buttons = driver.find_elements(By.CLASS_NAME, 'w8nwRe')\n",
    "for button in more_buttons:\n",
    "    button.click()\n",
    "    time.sleep(1)\n",
    "# get review\n",
    "reviews = soup.find_all('div', class_ = 'jJc9Ad')\n",
    "review = reviews[3]\n",
    "review.find('div', class_='MyEned').find('span').text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
